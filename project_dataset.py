# -*- coding: utf-8 -*-
"""Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JV411SyCsSI8MigEN3YN8RKa2_PsyLPS
"""

import torch
from torch.utils.data import Dataset
from torchvision.datasets import CIFAR100
from torchvision import transforms
import numpy as np
from PIL import Image

class SubCIFAR100(Dataset):
  """
  Fa due cose:
  - prende determiante labeles da cifrar100
  - le mappa come indicato
  - terza cosa giusto per rompere le palle
  """
  def __init__(self, labels_to_retrieve, label_mapping, train=True, transform=None, root='./CIFAR100', download=True):
    self.cifar100 = CIFAR100(root=root, train=train, download=download)
    self.transform = transform
    # Create a dict containing map[original label] = mapped label
    mapping = {original_label: mapped_label for original_label, mapped_label in zip(labels_to_retrieve, label_mapping)}

    # Retrieve indices of desired labels
    bool_idx = np.zeros(len(self.cifar100), dtype=bool)
    images = []
    labels = []
    for label in labels_to_retrieve:
      bool_idx += (self.cifar100.targets == label)
    # Turn bool mask into numeric labels
    indices = np.argwhere(bool_idx).flatten()
    for index in indices:
      img, label = self.cifar100[index]
      images.append(transforms.ToTensor()(img))
      labels.append(label)
    # Turn the lists into marvellous tensors
    self.data = torch.stack(images)
    self.targets = np.array([mapping[label] for label in labels], dtype='long')

  def __len__(self):
    """
    I wonder what this does.
    """
    return self.data.size(0)

  def pil_loader(self, tensor_img):
    f = transforms.ToPILImage()(tensor_img)
    return f.convert('RGB')

  def __getitem__(self, index):
    '''
    getitem should access an element through its index
    Args:
        index (int): Index
    Returns:
        tuple: (sample, target) where target is class_index of the target class.
    '''
    image = self.pil_loader(self.data[index])
    label = self.targets[index]
    
    if self.transform is not None:
        image = self.transform(image)
    
    return image, label

class CIFARFactory():
  """
  Factory class for retrieving re-mapped SubCifar100 datasets. Can accidentally destroy the world.
  """

  

  def __init__(self, seed=42, shuffle_classes=True, split_size=10):
    self.downloaded_dataset = False
    np.random.seed(seed=seed)
    self.original_labels = np.arange(100)
    if shuffle_classes == True:
      np.random.shuffle(self.original_labels)
    
    self.mapped_labels = np.arange(100)
    # Also geenrating classes in ranges 0 to N
    self.zero_N_labels = self.mapped_labels % split_size

    # Splitting batch of classes in subgroups
    self.original_sets = np.split(self.original_labels, split_size)
    self.mapped_sets = np.split(self.mapped_labels, split_size)
    self.zero_N_sets = np.split(self.zero_N_labels, split_size)

    self.train_transform = transforms.Compose([
                                      transforms.RandomHorizontalFlip(), # Randomly flip the image with probability of 0.5
                                      transforms.Pad(4), # Add padding
                                      transforms.RandomCrop(32),# Crops a random squares of the image
                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor
                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # https://gist.github.com/weiaicunzai/e623931921efefd4c331622c344d8151
                                      ])
    
    self.no_transform = transforms.Compose([
                                      transforms.ToTensor(),
                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])

  def get_train_dataset(self, step, zero_N=False, augmentation=True):
    if zero_N:
      mapping = self.zero_N_sets[step]
    else:
      mapping = self.mapped_sets[step]

    if augmentation:
      transform = self.train_transform
    else:
      transform = self.no_transform
    
    dataset = SubCIFAR100(self.original_sets[step], mapping, train=True, transform=transform, download=(not self.downloaded_dataset))
    self.downloaded_dataset = True
    return dataset

  def get_test_dataset(self, step):
    labels_to_retrieve = np.concatenate([self.original_sets[i] for i in range(step+1)])
    mapping = np.concatenate([self.mapped_sets[i] for i in range(step+1)])
    dataset = SubCIFAR100(labels_to_retrieve, mapping, train=False, transform=self.no_transform, download=(not self.downloaded_dataset))
    self.downloaded_dataset = True
    return dataset